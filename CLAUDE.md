# Claude AI Assistant Integration

This repository has Claude AI integrated via GitHub Actions. You can mention `@claude` in issues, pull requests, and comments to get AI assistance.

## ü§ñ How to Use

### In Issues
```markdown
I'm implementing Issue #16 (status command) but unsure about the best way
to structure the Rich table output. @claude can you suggest an approach?
```

### In Pull Requests
```markdown
@claude can you review this implementation and suggest improvements for
the error handling in the backup method?
```

### In Comments
```markdown
@claude what's the best practice for mocking subprocess calls in our tests
given our current testing patterns?
```

## üéØ What Claude Can Help With

### 1. Code Review & Suggestions
- Review implementations for best practices
- Suggest improvements for code quality
- Identify potential bugs or edge cases

### 2. Architecture Questions
- Explain existing patterns (VendorAdapter, Registry)
- Suggest approaches for new features
- Clarify design decisions

### 3. Testing Guidance
- Suggest test cases
- Help with pytest fixtures
- Advise on mocking strategies

### 4. Documentation
- Clarify unclear documentation
- Suggest docstring improvements
- Help with user guides

### 5. Troubleshooting
- Debug test failures
- Explain CI/CD issues
- Help with dependency problems

## ‚öôÔ∏è Setup (For Repository Owners)

### 1. Add Anthropic API Key
```bash
# In GitHub repository settings > Secrets and variables > Actions
# Add new repository secret:
# Name: ANTHROPIC_API_KEY
# Value: <your-anthropic-api-key>
```

### 2. Verify Workflow Permissions
The workflow needs:
- `contents: read` - Read repository code
- `issues: write` - Comment on issues
- `pull-requests: write` - Comment on PRs

These are configured in `.github/workflows/claude-assistant.yml`.

### 3. Test the Integration
Create a test issue:
```markdown
Title: Test Claude Integration
Body: @claude Hello! Can you confirm the integration is working?
```

Claude should respond within 1-2 minutes.

## üöÄ Features

### Automatic Context
Claude receives:
- Issue/PR title and body
- Comment text
- Repository context
- Development standards from `.claude/DEVELOPMENT_STANDARDS.md`

### Smart Responses
Claude provides:
- **Code examples** with proper syntax highlighting
- **Markdown formatting** for readability
- **Project-specific advice** based on our patterns
- **References** to existing code when relevant

### Triggers
Claude activates when `@claude` is mentioned in:
- ‚úÖ New issues
- ‚úÖ Edited issues
- ‚úÖ New comments on issues
- ‚úÖ Edited comments on issues
- ‚úÖ New pull requests
- ‚úÖ Edited pull requests
- ‚úÖ PR review comments

## üìã Examples

### Example 1: Implementation Help
**Question:**
```markdown
I'm working on Issue #58 (Configuration Schema Validation).
@claude what's the best approach for validating JSON schemas in Python?
Should we use jsonschema library or pydantic?
```

**Claude's Response:**
```markdown
For this project, I recommend **jsonschema** over pydantic because:

1. **Alignment with project patterns**: Your configs are already dicts/JSON
2. **Better error messages**: jsonschema provides detailed validation errors
3. **Schema reuse**: Can define schemas once, validate multiple times

Example implementation:

\`\`\`python
import json
from jsonschema import validate, ValidationError

CLAUDE_SCHEMA = {
    "type": "object",
    "properties": {
        "api_key": {"type": "string", "minLength": 10},
        "model": {"type": "string", "enum": ["sonnet", "opus"]},
    },
    "required": ["api_key"]
}

def validate_claude_config(config: dict) -> list[str]:
    """Validate Claude configuration against schema.

    Returns:
        List of validation error messages (empty if valid).
    """
    try:
        validate(instance=config, schema=CLAUDE_SCHEMA)
        return []
    except ValidationError as e:
        return [f"Validation error: {e.message}"]
\`\`\`

This approach:
- ‚úÖ Follows your existing patterns (functions return errors, not raise)
- ‚úÖ Provides user-friendly error messages
- ‚úÖ Easy to test (no external dependencies to mock)
- ‚úÖ Type-safe with mypy --strict

Would you like me to suggest how to integrate this into the VendorAdapter classes?

---
ü§ñ *Generated by Claude AI Assistant*
```

### Example 2: Test Strategy
**Question:**
```markdown
@claude I need to test the database migration framework. What test cases
should I cover for the MigrationManager.upgrade() method?
```

**Claude's Response:**
```markdown
For `MigrationManager.upgrade()`, I recommend these test categories based on your
existing testing patterns:

### 1. Happy Path Tests
- ‚úÖ `test_upgrade_applies_all_pending_migrations` - All migrations execute
- ‚úÖ `test_upgrade_with_target_version_stops_at_target` - Respects target
- ‚úÖ `test_upgrade_creates_backup_by_default` - Backup file exists

### 2. Edge Cases
- ‚úÖ `test_upgrade_returns_empty_list_if_no_pending` - Idempotent
- ‚úÖ `test_upgrade_skips_already_applied_migrations` - Version tracking
- ‚úÖ `test_upgrade_dry_run_validates_without_executing` - Dry-run mode

### 3. Error Handling
- ‚úÖ `test_upgrade_fails_gracefully_on_invalid_sql` - MigrationError raised
- ‚úÖ `test_upgrade_rolls_back_on_failure` - Backup preserved
- ‚úÖ `test_upgrade_reports_which_migrations_succeeded` - Error message clarity

### 4. Integration
- ‚úÖ `test_upgrade_updates_schema_version` - Metadata updated
- ‚úÖ `test_upgrade_records_in_migrations_table` - Tracking works

Example test using your fixture pattern:

\`\`\`python
def test_upgrade_applies_all_pending_migrations() -> None:
    """Test upgrade applies all pending migrations in order."""
    with tempfile.TemporaryDirectory() as temp_dir:
        db_path = Path(temp_dir) / "test.db"
        migrations_dir = Path(temp_dir) / "migrations"
        migrations_dir.mkdir()

        # Create 3 migrations
        (migrations_dir / "001_first.sql").write_text("CREATE TABLE t1 (id INTEGER);")
        (migrations_dir / "002_second.sql").write_text("CREATE TABLE t2 (id INTEGER);")
        (migrations_dir / "003_third.sql").write_text("CREATE TABLE t3 (id INTEGER);")

        # Initialize database
        with sqlite3.connect(db_path) as conn:
            conn.execute("CREATE TABLE dummy (id INTEGER)")
            conn.commit()

        # Run upgrade
        manager = MigrationManager(db_path, migrations_dir)
        applied = manager.upgrade(backup=False)

        # Verify
        assert len(applied) == 3
        assert [m.version for m in applied] == ["001", "002", "003"]
\`\`\`

This follows your patterns:
- ‚úÖ Uses temp directories (cleanup automatic)
- ‚úÖ Tests behavior, not implementation
- ‚úÖ Clear test name describes expectation
- ‚úÖ Single assertion per concept

---
ü§ñ *Generated by Claude AI Assistant*
```

### Example 3: Architecture Clarification
**Question:**
```markdown
@claude Why did we choose to rename `subagent_profiles` to `claude_agent_profiles`
instead of just adding a vendor_id column?
```

**Claude's Response:**
```markdown
Great question! The rename clarifies **ownership** and **scope**:

### Reason 1: Different Schemas
Claude agents have specific fields that other vendors don't:
- `tools`: Comma-separated tool list
- `model`: Claude-specific model names
- `version`: Agent version (Claude-specific)

Gemini has different fields:
- `mcp_servers`: List of MCP server configs
- No "tools" concept

OpenAI has different fields again:
- `instructions`: System prompt
- `functions`: Function calling specs

### Reason 2: Polymorphism
We created the **capabilities** table for vendor-agnostic tracking:
```sql
CREATE TABLE capabilities (
    vendor_id TEXT,
    capability_type TEXT,  -- 'agent', 'skill', 'mcp_server', 'tool'
    capability_name TEXT,
    metadata JSON  -- Vendor-specific fields go here
);
```

This allows:
- ‚úÖ Universal queries across all vendors
- ‚úÖ Vendor-specific schemas for detailed data
- ‚úÖ Easy addition of new vendor types

### Reason 3: Migration Safety
Renaming is safer than adding columns:
- Old Claude tools still work (they use `claude_agent_profiles`)
- No breaking changes to existing SessionLogger
- Clear separation of concerns

### Pattern Summary
- **capabilities**: Vendor-agnostic, for comparisons
- **claude_agent_profiles**: Claude-specific, rich metadata
- **gemini_mcp_configs** (future): Gemini-specific
- **openai_function_profiles** (future): OpenAI-specific

This follows the same pattern as `vendor_versions` (common fields) + `metadata` JSON
(vendor-specific fields).

---
ü§ñ *Generated by Claude AI Assistant*
```

## üõ°Ô∏è Privacy & Security

### What Claude Sees
- ‚úÖ Public repository content
- ‚úÖ Issue/PR titles and bodies
- ‚úÖ Comment text
- ‚ùå Private repository secrets
- ‚ùå Environment variables
- ‚ùå API keys (except to authenticate)

### Data Handling
- **No storage**: Anthropic doesn't store conversation history
- **No training**: Your data isn't used for model training
- **API only**: Uses Anthropic API (not Claude Code desktop)

### Best Practices
- ‚ùå Don't share real API keys in issues
- ‚ùå Don't post credentials or secrets
- ‚úÖ Use example data in questions
- ‚úÖ Redact sensitive information

## üîß Troubleshooting

### Claude Doesn't Respond
1. **Check workflow ran**: Go to Actions tab, verify workflow triggered
2. **Check logs**: Click on the workflow run to see error messages
3. **Verify API key**: Ensure `ANTHROPIC_API_KEY` secret is set
4. **Check mention**: Ensure you typed `@claude` (case-sensitive)

### Response is Cut Off
- Claude uses max 2000 tokens for responses
- Ask more specific questions for detailed answers
- Can ask follow-up questions in new comments

### Wrong Context
- Claude sees the current issue/PR/comment only
- For broader context, provide links to relevant code
- Reference issue numbers for context: "See #16 for background"

## üìö Resources

- **Claude API Docs**: https://docs.anthropic.com/
- **GitHub Actions**: https://docs.github.com/actions
- **Our Standards**: `.claude/DEVELOPMENT_STANDARDS.md`
- **Workflow File**: `.github/workflows/claude-assistant.yml`

## üí° Tips for Better Responses

### 1. Be Specific
**‚ùå Vague**: "@claude how do I test this?"
**‚úÖ Specific**: "@claude how do I test the backup() method with tar.gz file creation?"

### 2. Provide Context
**‚ùå No context**: "@claude is this the right approach?"
**‚úÖ With context**: "@claude given our VendorAdapter pattern, is this the right approach for Gemini's MCP server detection?"

### 3. Ask One Thing
**‚ùå Multiple**: "@claude review this code and also suggest tests and explain the architecture"
**‚úÖ Focused**: "@claude can you review this implementation for potential edge cases?"

### 4. Reference Standards
**‚úÖ Good**: "@claude does this follow our 95%+ coverage requirement? If not, what test cases should I add?"

## üéì Learning Mode

Use Claude to learn the codebase:
- "@ claude explain how VendorRegistry discovers vendors"
- "@claude walk me through the database migration process"
- "@claude what's the purpose of the agent_tracker.json file?"

## ü§ù Contributing

When adding Claude to your own repositories:
1. Copy `.github/workflows/claude-assistant.yml`
2. Add `ANTHROPIC_API_KEY` secret
3. Customize the prompt in the workflow for your project
4. Test with a sample issue

---

**Questions about this integration?** Ask @claude in any issue! üöÄ
